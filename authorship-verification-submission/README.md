# Generative AI Authorship Verification

This directory contains the implementation of the NLP Task 'Generative AI Authorship Verification'. which determines if a given document was generated by an LLM. The training dataset consists of 1,774 news articles, half of which were written by humans and the other half by an LLM. A linear regression model is used which makes predictions based on the document's word frequencies.

### Files

* The Dockerfile includes instructions for building the image and adds the Python script and persisted data to the it. It also installs additional dependencies from nltk required for text preprocessing.

* The vectorizer.joblib file contains the vectorizer instance which contains vocabulary from the training dataset. The same instance will be loaded to create the vector representation of the validation/training dataset's text. The model.joblib file contains the model which has been trained on the training dataset and can be loaded to predict values for the validation/training dataset.

* The train.py file preprocesses the training data, extracts its features (word frequencies), and trains a Logistic Regression model based on the features and their labels. The model and the vectorizer (used to extract features) are dumped into .joblib files to load during running stage.

* The run.py file loads the validation/test data, preprocesses it, and then extracts its features. The saved vectorizer instance is used for this purpose. It then loads the saved model and predicts values for the labels based on the data's features. The predicted values are written into a 'predictions.jsonl' file.

### Additional Libraries

* **nltk** for text-preprocessing
* **scikit-learn** to extract features and train the model

